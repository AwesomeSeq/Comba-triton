{ "expand_v": 1,
  "use_gate": true,
  "fuse_cross_entropy": true,
  "fuse_norm": true,
  "hidden_size": 2048,
  "model_type": "comba",
  "num_heads": 4,
  "head_dim": 256,
  "initializer_range": 0.006,
  "num_hidden_layers": 24,
  "A_type": "iplr",
  "qk_sim": true,
  "tie_word_embeddings": false}